{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8356de88-942d-4dc4-bb92-f39953795199",
   "metadata": {},
   "source": [
    "**1- Normalizasyon**\r\n",
    "   \r\n",
    "   Veri setinizi normalleştirmek, farklı ölçeklerde olan özelliklerin modeller tarafından daha etkili bir şekilde işlenmesini sağlar. Bu normalleştirme işlemi, özellikle uzaklık tabanlı algoritmalar için kritiktir; çünkü özellikler arasındaki ölçek farklılıkları, modelin performansını doğrudan etkileyebilir.\r\n",
    "\r\n",
    "Yaygın olarak kullanılan normalleştirme yöntemlerinden biri Min-Max normalleştirmesidir. Bu yöntem, tüm değerleri belirli bir aralığa dönüştürerek veri setini ölçeklendirir. Aslında elimizde bulunan tüm columlar için aynı aralıkta verilere dönüştürülmesi sağlanıyor. Önreğin maaş bilgisini de 0-1 arasında ifade ediyoruz, yaş bilgisini de buda bize veriler üzerinden çıkarım yapmamızı kolaylaştırıyor.\r\n",
    "\r\n",
    "Min-Max Formül:\r\n",
    "\r\n",
    "Xnormalizasyon = (X−Xmin) / (Xmax−Xmin)\r\n",
    "\r\n",
    "Burada, X özelliğin (sütunun) orijinal değerini, Xmin o özelliğin minimum değerini ve Xmax ise maksimum değerini temsil ediyor.\r\n",
    "Normalizasyon ilemleri için pyhton’un pandas kütüphanesinden yararlanabiliriz. Öncelikle bu kütüphanenin bize sağladığı DataFrame’yapısı ile veriyi okuyup Data Frame’ yükleyelim. Sonrasında Normalizasyon formülünü de kullanarak bu veri seti üzerinden normazlisasyon işlemini yapalım \r\n",
    "\r\n",
    "Normalizasyon veri seti üzerinde daha sağlıklı çıkarımlar yapmamızı sağlayan temel adımlardan bir tanesidir. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a80cb3c6-6e8a-428f-afc4-908bd8507e1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gebelikler</th>\n",
       "      <th>Glikoz</th>\n",
       "      <th>KanBasinci</th>\n",
       "      <th>Cilt Kalinligi</th>\n",
       "      <th>Insülin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiyabetSoyagacıFonksiyonu</th>\n",
       "      <th>Yas</th>\n",
       "      <th>Sonuc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.352941</td>\n",
       "      <td>0.743719</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500745</td>\n",
       "      <td>0.234415</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.427136</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.292929</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396423</td>\n",
       "      <td>0.116567</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.919598</td>\n",
       "      <td>0.524590</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.347243</td>\n",
       "      <td>0.253629</td>\n",
       "      <td>0.183333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.447236</td>\n",
       "      <td>0.540984</td>\n",
       "      <td>0.232323</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.418778</td>\n",
       "      <td>0.038002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688442</td>\n",
       "      <td>0.327869</td>\n",
       "      <td>0.353535</td>\n",
       "      <td>0.198582</td>\n",
       "      <td>0.642325</td>\n",
       "      <td>0.943638</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.582915</td>\n",
       "      <td>0.606557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.381520</td>\n",
       "      <td>0.052519</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.391960</td>\n",
       "      <td>0.409836</td>\n",
       "      <td>0.323232</td>\n",
       "      <td>0.104019</td>\n",
       "      <td>0.461997</td>\n",
       "      <td>0.072588</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.588235</td>\n",
       "      <td>0.577889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526080</td>\n",
       "      <td>0.023911</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.989950</td>\n",
       "      <td>0.573770</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.641844</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.034159</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.470588</td>\n",
       "      <td>0.628141</td>\n",
       "      <td>0.786885</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065756</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gebelikler    Glikoz  KanBasinci  Cilt Kalinligi   Insülin       BMI  \\\n",
       "0    0.352941  0.743719    0.590164        0.353535  0.000000  0.500745   \n",
       "1    0.058824  0.427136    0.540984        0.292929  0.000000  0.396423   \n",
       "2    0.470588  0.919598    0.524590        0.000000  0.000000  0.347243   \n",
       "3    0.058824  0.447236    0.540984        0.232323  0.111111  0.418778   \n",
       "4    0.000000  0.688442    0.327869        0.353535  0.198582  0.642325   \n",
       "5    0.294118  0.582915    0.606557        0.000000  0.000000  0.381520   \n",
       "6    0.176471  0.391960    0.409836        0.323232  0.104019  0.461997   \n",
       "7    0.588235  0.577889    0.000000        0.000000  0.000000  0.526080   \n",
       "8    0.117647  0.989950    0.573770        0.454545  0.641844  0.454545   \n",
       "9    0.470588  0.628141    0.786885        0.000000  0.000000  0.000000   \n",
       "\n",
       "   DiyabetSoyagacıFonksiyonu       Yas  Sonuc  \n",
       "0                   0.234415  0.483333    1.0  \n",
       "1                   0.116567  0.166667    0.0  \n",
       "2                   0.253629  0.183333    1.0  \n",
       "3                   0.038002  0.000000    0.0  \n",
       "4                   0.943638  0.200000    1.0  \n",
       "5                   0.052519  0.150000    0.0  \n",
       "6                   0.072588  0.083333    1.0  \n",
       "7                   0.023911  0.133333    0.0  \n",
       "8                   0.034159  0.533333    1.0  \n",
       "9                   0.065756  0.550000    1.0  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Veri setini okutulması\n",
    "df = pd.read_csv('veri-seti.txt', header=None, sep='\\t')\n",
    "\n",
    "# Sütünların isimlendirilmesi belirleme\n",
    "columns = ['Gebelikler', 'Glikoz', 'KanBasinci', 'Cilt Kalinligi', 'Insülin', 'BMI', 'DiyabetSoyagacıFonksiyonu', 'Yas', 'Sonuc']\n",
    "df.columns = columns\n",
    "\n",
    "# Min-Max Normalizasyonu uygulayalım (Formül ile)\n",
    "df_normalized = (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "# İlk 10 satırı yazdırıp kontrol edelim\n",
    "df_normalized.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf434844-d675-40c0-a99f-b9b777a8932a",
   "metadata": {},
   "source": [
    "PCA (Principal Component Analysis), çok değişkenli veri setlerindeki değişkenlik yapısını anlamak ve boyut indirgeme yapmak için kullanılan istatistiksel bir yöntemdir. Temel amacı, veri setindeki değişkenler arasındaki ilişkileri anlamak ve bu ilişkileri daha az değişken kullanarak nasıl ifade edilebilir tespit ederek yeni değişkenler oluşturmaktır. \r\n",
    "PCA'nın çalışma prensibi, veri setindeki değişkenlik yapısını temsil eden temel bileşenleri (principal components) belirlemektir. Bu temel bileşenler, orijinal değişkenlerin lineer kombinasyonlarıdır ve veri setindeki değişkenlik yapısını en iyi şekilde açıklamak için seçilirler.\n",
    "\n",
    " PCA, veri setindeki değişkenlik miktarına göre temel bileşenleri sıralar, böylece ilk temel bileşen, veri setindeki toplam değişkenliğin en büyük kısmını temsil eder.\r\n",
    "Boyut indirgeme sürecinde, PCA ilk temel bileşenlerden başlayarak gereksiz veya düşük varyanslı olanları kaldırarak yeni bir değişkenler kümesi oluşturur. Bu yeni değişkenler, orijinal veri setinin boyutunu azaltırken, mümkün olduğunca çok değişkenlik yapısını korumaya çalışır\n",
    ".\r\n",
    "PCA'nın temel amacı, çok boyutlu veri setlerindeki karmaşık ilişkileri anlamak ve daha az boyutlu bir uzayda bu ilişkileri temsil etmektir. Bu, veri analizi, veri görselleştirme ve makine öğrenmesi gibi alanlarda kullanılan güçlü bir tekniktir.\r\n",
    "\r\n",
    "LDA (Linear Discriminant Analysis), sınıflandırma problemlerinde kullanılan bir boyut indirgeme tekniğidir. Amacı, veri setindeki sınıflar arasındaki farkı en iyi şekilde yansıtan bir alt uzay oluşturmaktır. Bu sayede, sınıfları en iyi şekilde ayıran özelliklerin bulunması ve sınıflandırma performansının artırılması hedeflnir.\r\n",
    "\r\n",
    "LDA, PCA'ya benzer şekilde çalışır, ancak temel farkı, sınıf bilgisini kullanmasıdır. PCA denetimsiz bir öğrenme yöntemi iken, LDA denetimli bir öğrenme yöntemidir. LDA, sınıf etiketlerini kullanarak, veri setindeki sınıflar arasındaki farkı maksimize eden yeni bir öznitelik alt uzayı oluturur.\r\n",
    "\r\n",
    "LDA'nın çalışma prensibi, veri setindeki sınıflar arasındaki değişkenliği en iyi şekilde temsil eden lineer diskriminantları (linear discriminants) belirlemektir. Bu diskriminantlar, veri setindeki sınıflar arasındaki farkı en iyi şekilde açıklayan lineer kombinasyonlardır. LDA, bu diskriminantları sıralar ve en büyük ayrımı sağlayan diskriminantlaı seçer.\r\n",
    "\r\n",
    "Boyut indirgeme sürecinde, LDA, belirlenen diskriminantları kullanarak yeni bir değişkenler kümesi oluşturur. Bu yeni değişkenler, orijinal veri setinin boyutunu azaltırken, sınıflar arasındaki farkı en iyi şekilde koruma çalışır.\r\n",
    "\r\n",
    "LDA, sınıflandırma problemlerinde boyut indirgeme yapmak için kullanılan güçlü bir tekniktir. Bu, özellik seçimi, desen tanıma ve sınıflandırma gibi uygulamalarda yaygın olara\n",
    "\n",
    " kullanılır.\r\n",
    "Bu iki yöntemi karşılaştırmak gerekirse, PCA denetimsiz bir öğrenme yöntemidir, yani sınıf etiketlerini göz önünde bulundurmaz. Sadece değişkenliği maksimize ederek boyut indirgeme yapar. Diğer yandan, LDA denetimli bir öğrenme yöntemidir ve sınıf etiketlerini kullanır. Bu nedenle, sınıf ayrımını göz önünde bulundurarak daha ayrıntılı bir boyut indirgeme yapar. LDA daha çok sınıfın olduğu yapılarda kullanılır.\r\n",
    "tax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d35a9b12-7799-489c-9116-036b347b8326",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Oranı: [1.]\n",
      "PCA Açıklanan VaryansOranı: [0.31192249 0.21186663]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Özellikler ve hedef ayırma (Hedef sütun adınızı doğru şekilde güncelleyin)\n",
    "X = df_normalized.drop('Sonuc', axis=1)   \n",
    "y = df_normalized['Sonuc']   \n",
    "\n",
    "# PCA  uygulaması\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X)\n",
    "  \n",
    "# LDA uygulaması\n",
    "lda = LDA(n_components=1)  # LDA için maksimum bileşen sayısı (sınıf sayısı - 1)\n",
    "X_lda = lda.fit_transform(X, y)\n",
    "\n",
    "\n",
    "# LDA ve PCA sonuçların yazdırılması:\n",
    "print(\"LDA Oranı:\", lda.explained_variance_ratio_ if hasattr(lda, 'explained_variance_ratio_') else \"N/A\")\n",
    "print(\"PCA Açıklanan VaryansOranı:\", pca.explained_variance_ratio_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24e1a977-5e7b-4c2d-a561-483bb2b8de1f",
   "metadata": {},
   "source": [
    "**3. Çoklu Doğrusal ve Multinominal Lojistik Regresyon Uygulanması*** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b8e9dfda-9cc1-450b-a67b-6802a08ed896",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katsayılar:\n",
      " [[ 0.4505206   2.65118931 -0.24999553  0.03039025 -0.06304149  2.16599472\n",
      "   0.45399225  0.90638614]]\n",
      "\n",
      "Kesme terimi: [-3.25065341]\n",
      "\n",
      "Doğruluk oranı: 0.7359307359307359\n",
      "\n",
      "Sınıflandırma raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.78      0.82      0.80       151\n",
      "         1.0       0.63      0.57      0.60        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.71      0.70      0.70       231\n",
      "weighted avg       0.73      0.74      0.73       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# Veri setini eğitim %70 ve test setlerine %30 ayırma\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Lojistik Regresyon modeli eğitimi\n",
    "log_reg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "# Modelin katsayılarını yazdırılması\n",
    "print(\"Katsayılar:\\n\", log_reg.coef_)\n",
    "print(\"\\nKesme terimi:\", log_reg.intercept_)\n",
    "\n",
    "# Performans değerlendirme(Test verisi ile)\n",
    "y_pred = log_reg.predict(X_test)\n",
    "print(\"\\nDoğruluk oranı:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nSınıflandırma raporu:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df4bb0-6735-4a6f-9bda-d94c6b7e704c",
   "metadata": {},
   "source": [
    "Bu sonuçlar, modelin diyabet teşhisi konusunda iyi bir doğruluk oranına sahip olduğunu, ancak özellikle pozitif sınıf için (diyabet olanlar) duyarlılık ve kesinliğin daha da iyileştirilebileceğini göstermektedir. Yanlış negatif ve yanlış pozitif oranlarının azaltılması için modelin daha da optimize edilmesi gerekebilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4b7e96-5187-4a46-af29-6aa9e14d1eaa",
   "metadata": {},
   "source": [
    "**4. Karar Ağacı Sınıflandırma Uygulaması**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "76dabd6c-9341-4995-b95c-b87b9f6bd07c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk (Accuracy): 0.7012987012987013\n",
      "\n",
      "Confusion Matrix:\n",
      " [[107  44]\n",
      " [ 25  55]]\n",
      "\n",
      "Sınıflandırma Raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.71      0.76       151\n",
      "         1.0       0.56      0.69      0.61        80\n",
      "\n",
      "    accuracy                           0.70       231\n",
      "   macro avg       0.68      0.70      0.69       231\n",
      "weighted avg       0.72      0.70      0.71       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n",
    "\n",
    "# Karar Ağacı modelini eğitme\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "decision_tree.fit(X_train, y_train)\n",
    "\n",
    "# Test veri seti üzerinde modelin performansını değerlendirme\n",
    "y_pred_dt = decision_tree.predict(X_test)\n",
    "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
    "conf_matrix_dt = confusion_matrix(y_test, y_pred_dt)\n",
    "class_report_dt = classification_report(y_test, y_pred_dt)\n",
    "\n",
    "print(\"Doğruluk (Accuracy):\", accuracy_dt)\n",
    "print(\"\\nConfusion Matrix:\\n\", conf_matrix_dt)\n",
    "print(\"\\nSınıflandırma Raporu:\\n\", class_report_dt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b994c2a9-01da-4957-83f7-9002ef9b4b6c",
   "metadata": {},
   "source": [
    "Karar Ağacı modeli, diyabet teşhisi konusunda kabul edilebilir bir doğruluk oranı sunmuş, ancak yanlış pozitif ve yanlış negatif oranları dikkate alındığında modelin performansının daha da iyileştirilebileceği görülmektedir. Diyabet olmayanları tespit etme konusunda daha yüksek bir kesinlik sunarken, diyabet olan hastaların tespitinde duyarlılığı artırılabilir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe69b539-c0fe-4382-a693-5c3bda0d2ebb",
   "metadata": {},
   "source": [
    "**5. Naive Bayes Sınıflandırma Uygulaması**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec20807a-0795-4b82-835c-59d90aeeacd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk oranı: 0.7445887445887446\n",
      "\n",
      "Confusion Matrix:\n",
      " [[119  32]\n",
      " [ 27  53]]\n",
      "\n",
      "Sınıflandırma raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.82      0.79      0.80       151\n",
      "         1.0       0.62      0.66      0.64        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.73      0.72       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Naive Bayes modeli eğitimi\n",
    "naive_bayes = GaussianNB()\n",
    "naive_bayes.fit(X_train, y_train)\n",
    "\n",
    "# Test verisi üzerinde performans değerlendirme\n",
    "y_pred_nb = naive_bayes.predict(X_test)\n",
    "print(\"Doğruluk oranı:\", accuracy_score(y_test, y_pred_nb))\n",
    "print(\"\\nConfusion Matrix:\\n\", confusion_matrix(y_test, y_pred_nb))\n",
    "print(\"\\nSınıflandırma raporu:\\n\", classification_report(y_test, y_pred_nb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500fc756-355b-4a7a-aba8-30a772596d5d",
   "metadata": {},
   "source": [
    "Naive Bayes modeli, test verisi üzerinde %74.46 gibi bir doğruluk oranı ile kabul edilebilir bir performans göstermiştir. Model, diyabet olmayanları oldukça iyi bir kesinlikle tanırken, diyabet olan hastaların tespitinde duyarlılığı ve kesinliği daha da artırılabilir. Bu sonuçlar, modelin iyileştirilmesi için ek parametre ayarlamaları veya farklı sınıflandırma yöntemlerinin denenmesi gerektiğini göstermektedir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
